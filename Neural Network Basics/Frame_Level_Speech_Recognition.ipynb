{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F9ERgBpbcMmB"
      },
      "source": [
        "#Frame-Level Speech Recognition"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z4vZbDmJvMp1"
      },
      "source": [
        "# Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rwYu9sSUnSho",
        "outputId": "862d1fb3-9fbe-4e3d-a5ee-d678f9c1b4fb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K     |████████████████████████████████| 1.8 MB 14.9 MB/s \n",
            "\u001b[K     |████████████████████████████████| 162 kB 73.3 MB/s \n",
            "\u001b[K     |████████████████████████████████| 181 kB 74.8 MB/s \n",
            "\u001b[K     |████████████████████████████████| 63 kB 1.8 MB/s \n",
            "\u001b[K     |████████████████████████████████| 158 kB 90.2 MB/s \n",
            "\u001b[K     |████████████████████████████████| 157 kB 90.8 MB/s \n",
            "\u001b[K     |████████████████████████████████| 157 kB 87.5 MB/s \n",
            "\u001b[K     |████████████████████████████████| 157 kB 88.0 MB/s \n",
            "\u001b[K     |████████████████████████████████| 157 kB 87.3 MB/s \n",
            "\u001b[K     |████████████████████████████████| 157 kB 81.1 MB/s \n",
            "\u001b[K     |████████████████████████████████| 157 kB 75.2 MB/s \n",
            "\u001b[K     |████████████████████████████████| 157 kB 59.1 MB/s \n",
            "\u001b[K     |████████████████████████████████| 156 kB 88.8 MB/s \n",
            "\u001b[?25h  Building wheel for pathtools (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "!pip install torchsummaryX wandb --quiet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qI4qfx7tiBZt",
        "outputId": "d0e549d7-989b-429c-d7d5-21235a0dc234"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Device:  cuda\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "from torchsummaryX import summary\n",
        "import sklearn\n",
        "import gc\n",
        "import zipfile\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "import os\n",
        "import datetime\n",
        "import wandb\n",
        "import sklearn.metrics\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "print(\"Device: \", device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8yBgXjKV1O0Z",
        "outputId": "1e68c6c1-81b8-40e2-f02c-a8b37b2738f9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N-9qE20hmCgQ"
      },
      "outputs": [],
      "source": [
        "### PHONEME LIST\n",
        "PHONEMES = [\n",
        "            'SIL',   'AA',    'AE',    'AH',    'AO',    'AW',    'AY',  \n",
        "            'B',     'CH',    'D',     'DH',    'EH',    'ER',    'EY',\n",
        "            'F',     'G',     'HH',    'IH',    'IY',    'JH',    'K',\n",
        "            'L',     'M',     'N',     'NG',    'OW',    'OY',    'P',\n",
        "            'R',     'S',     'SH',    'T',     'TH',    'UH',    'UW',\n",
        "            'V',     'W',     'Y',     'Z',     'ZH',    '<sos>', '<eos>']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZIi0Big7vPa9"
      },
      "source": [
        "# Kaggle"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BBCbeRhixGM7"
      },
      "source": [
        "This section contains code that install kaggle's API, "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TPBUd7Cnl-Rx",
        "outputId": "1a9d3c2d-dc9c-4f1c-ce4a-6a71c05fe602"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting kaggle==1.5.8\n",
            "  Downloading kaggle-1.5.8.tar.gz (59 kB)\n",
            "\u001b[K     |████████████████████████████████| 59 kB 4.8 MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: kaggle\n",
            "  Building wheel for kaggle (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for kaggle: filename=kaggle-1.5.8-py3-none-any.whl size=73275 sha256=8a2c69ef7229757100c57327ca5fc64a1e23e02b206e9a29f1d674c85f393f56\n",
            "  Stored in directory: /root/.cache/pip/wheels/de/f7/d8/c3902cacb7e62cb611b1ad343d7cc07f42f7eb76ae3a52f3d1\n",
            "Successfully built kaggle\n",
            "Installing collected packages: kaggle\n",
            "  Attempting uninstall: kaggle\n",
            "    Found existing installation: kaggle 1.5.12\n",
            "    Uninstalling kaggle-1.5.12:\n",
            "      Successfully uninstalled kaggle-1.5.12\n",
            "Successfully installed kaggle-1.5.8\n"
          ]
        }
      ],
      "source": [
        "!pip install --upgrade --force-reinstall --no-deps kaggle==1.5.8\n",
        "!mkdir /root/.kaggle\n",
        "\n",
        "with open(\"/root/.kaggle/kaggle.json\", \"w+\") as f:\n",
        "    f.write('{\"username\":\"jingrugongruby\",\"key\":\"\"}') \n",
        "    # Put your kaggle username & key here\n",
        "\n",
        "!chmod 600 /root/.kaggle/kaggle.json"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "if2Somqfbje1",
        "outputId": "9db7e79e-0240-49d5-a4d8-1f0339a0a35e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading 11-785-f22-hw1p2.zip to /content\n",
            " 99% 2.12G/2.13G [00:08<00:00, 253MB/s]\n",
            "100% 2.13G/2.13G [00:08<00:00, 263MB/s]\n"
          ]
        }
      ],
      "source": [
        "# commands to download data from kaggle\n",
        "\n",
        "!kaggle competitions download -c 11-785-f22-hw1p2\n",
        "!mkdir '/content/data'\n",
        "\n",
        "!unzip -qo '11-785-f22-hw1p2.zip' -d '/content/data'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vuzce0_TdcaR"
      },
      "source": [
        "# Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YpLCvi3AJC5z"
      },
      "outputs": [],
      "source": [
        "# Dataset class to load train and validation data\n",
        "\n",
        "class AudioDataset(torch.utils.data.Dataset):\n",
        "\n",
        "    def __init__(self, data_path, context, offset=0, partition= \"train\", limit=-1): \n",
        "\n",
        "        self.context = context\n",
        "        self.offset = offset\n",
        "        self.data_path = data_path\n",
        "\n",
        "        self.mfcc_dir = [\"/train-clean-100/mfcc\" if partition == \"train\" else \"/dev-clean/mfcc\"][0]\n",
        "        \n",
        "        self.transcript_dir = [\"/train-clean-100/transcript\" if partition == \"train\" else \"/dev-clean/transcript\"][0]\n",
        "        mfcc_names = sorted(os.listdir(self.data_path+self.mfcc_dir)) \n",
        "        transcript_names = sorted(os.listdir(self.data_path+self.transcript_dir))\n",
        "\n",
        "        assert len(mfcc_names) == len(transcript_names) # Making sure that we have the same no. of mfcc and transcripts\n",
        "\n",
        "        self.mfccs, self.transcripts = [], []\n",
        "\n",
        "        \n",
        "        # Iterate through mfccs and transcripts\n",
        "        for i in range(0, len(mfcc_names)):\n",
        "        #   Load a single mfcc\n",
        "            mfcc = np.load(self.data_path+self.mfcc_dir+\"/\"+mfcc_names[i],allow_pickle=True)\n",
        "            mfcc -= (np.mean(mfcc, axis=0) + 1e-8)\n",
        "        #   Optionally do Cepstral Normalization of mfcc\n",
        "        #   Load the corresponding transcript\n",
        "            transcript = np.load(self.data_path+self.transcript_dir+\"/\"+transcript_names[i],allow_pickle=True)\n",
        "            # Remove [SOS] and [EOS] from the transcript (Is there an efficient way to do this \n",
        "            # without traversing through the transcript?)\n",
        "            index1 = np.where(transcript=='<sos>')\n",
        "            index2 = np.where(transcript=='<eos>')\n",
        "            transcript = np.delete(transcript,[index1,index2])\n",
        "            \n",
        "        #   Append each mfcc to self.mfcc, transcript to self.transcript\n",
        "            self.mfccs.append(mfcc)\n",
        "            self.transcripts.append(transcript)\n",
        "\n",
        "        \n",
        "\n",
        "        # NOTE:\n",
        "        # Each mfcc is of shape T1 x 15, T2 x 15, ...\n",
        "        # Each transcript is of shape (T1+2) x 15, (T2+2) x 15 before removing [SOS] and [EOS]\n",
        "\n",
        "        self.mfccs = np.concatenate(self.mfccs,axis = 0)\n",
        "        self.length = len(self.mfccs)\n",
        "\n",
        "        self.transcripts = np.concatenate(self.transcripts,axis = 0)\n",
        "        padding_width = [(self.context, self.context), (0,0)]\n",
        "\n",
        "        self.mfccs = np.pad(self.mfccs, padding_width, mode='constant', constant_values=0)\n",
        "        \n",
        "\n",
        "        # These are the available phonemes in the transcript\n",
        "        self.phonemes = [\n",
        "            'SIL',   'AA',    'AE',    'AH',    'AO',    'AW',    'AY',  \n",
        "            'B',     'CH',    'D',     'DH',    'EH',    'ER',    'EY',\n",
        "            'F',     'G',     'HH',    'IH',    'IY',    'JH',    'K',\n",
        "            'L',     'M',     'N',     'NG',    'OW',    'OY',    'P',\n",
        "            'R',     'S',     'SH',    'T',     'TH',    'UH',    'UW',\n",
        "            'V',     'W',     'Y',     'Z',     'ZH', '<sos>', '<eos>']\n",
        "          \n",
        "        # But the neural network cannot predict strings as such. Instead we map these phonemes to integers\n",
        "        for i,p in enumerate(self.transcripts):\n",
        "          self.transcripts[i] = self.phonemes.index(p)\n",
        "        \n",
        "        self.transcripts = self.transcripts.astype(int)\n",
        "        \n",
        "        # Now, if an element in self.transcript is 0, it means that it is 'SIL' (as per the above example)\n",
        "\n",
        "        # Length of the dataset is now the length of concatenated mfccs/transcripts\n",
        "        \n",
        "\n",
        "    def __len__(self):\n",
        "        return self.length\n",
        "\n",
        "    def __getitem__(self, ind):\n",
        "        \n",
        "        frames = self.mfccs[ind:ind+2*self.context+1] \n",
        "        # After slicing, you get an array of shape 2*context+1 x 15. But our MLP needs 1d data and not 2d.\n",
        "        frames = frames.flatten() # Flatten to get 1d data\n",
        "\n",
        "        frames = torch.FloatTensor(frames) # Convert to tensors\n",
        "        phoneme = torch.tensor(self.transcripts[ind])       \n",
        "\n",
        "        return frames, phoneme"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e8KfVP39S6o7"
      },
      "outputs": [],
      "source": [
        "class AudioTestDataset(torch.utils.data.Dataset):\n",
        "\n",
        "    def __init__(self, data_path, context, offset=0, limit=-1): \n",
        "\n",
        "        self.context = context\n",
        "        self.offset = offset\n",
        "        self.data_path = data_path\n",
        "\n",
        "        self.mfcc_dir = [\"/test-clean/mfcc\"][0]\n",
        "        mfcc_names = sorted(os.listdir(self.data_path+self.mfcc_dir)) # List files in sefl.mfcc_dir_dir using os.listdir in sorted order, optionally subset using limit to slice the number of files you load\n",
        "        self.mfccs = []\n",
        "\n",
        "        \n",
        "        # Iterate through mfccs and transcripts\n",
        "        for i in range(0, len(mfcc_names)):\n",
        "        #   Load a single mfcc\n",
        "            mfcc = np.load(self.data_path+self.mfcc_dir+\"/\"+mfcc_names[i],allow_pickle=True)\n",
        "            mfcc -= (np.mean(mfcc, axis=0) + 1e-8)\n",
        "        #   Append each mfcc to self.mfcc, transcript to self.transcript\n",
        "            self.mfccs.append(mfcc)\n",
        "\n",
        "        \n",
        "\n",
        "        # NOTE:\n",
        "        # Each mfcc is of shape T1 x 15, T2 x 15, ...\n",
        "        # Each transcript is of shape (T1+2) x 15, (T2+2) x 15 before removing [SOS] and [EOS]\n",
        "\n",
        "        # Concatenate all mfccs in self.mfccs such that the final shape is T x 15 (Where T = T1 + T2 + ...) \n",
        "        self.mfccs = np.concatenate(self.mfccs,axis = 0)\n",
        "        self.length = len(self.mfccs)\n",
        "\n",
        "        padding_width = [(self.context, self.context), (0,0)]\n",
        "\n",
        "        self.mfccs = np.pad(self.mfccs, padding_width, mode='constant', constant_values=0)    \n",
        "        \n",
        "        # Length of the dataset is now the length of concatenated mfccs/transcripts\n",
        "        \n",
        "\n",
        "    def __len__(self):\n",
        "        return self.length\n",
        "\n",
        "    def __getitem__(self, ind):\n",
        "        \n",
        "        frames = self.mfccs[ind:ind+2*self.context+1] # Based on context and offset, return a frame at given index with context frames to the left, and right.\n",
        "        # After slicing, you get an array of shape 2*context+1 x 15. But our MLP needs 1d data and not 2d.\n",
        "        frames = frames.flatten() # Flatten to get 1d data\n",
        "\n",
        "        frames = torch.FloatTensor(frames) # Convert to tensors\n",
        "        \n",
        "\n",
        "        return frames\n",
        "    "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qNacQ8bpt9nw"
      },
      "source": [
        "# Parameters Configuration"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WE7tsinAuLNy"
      },
      "source": [
        "Storing your parameters and hyperparameters in a single configuration dictionary makes it easier to keep track of them during each experiment. It can also be used with weights and biases to log your parameters for each experiment and keep track of them across multiple experiments. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PmKwlFqgt_Zq"
      },
      "outputs": [],
      "source": [
        "config = {\n",
        "    'epochs': 90,\n",
        "    'batch_size' :16384,\n",
        "    'context' :50,\n",
        "    'offset':0,\n",
        "    'learning_rate' : 0.001,\n",
        "    'architecture' : 'high-cutoff1',\n",
        "    'dropout':0.25 ,\n",
        "    'weight_decay': 0.0001\n",
        "    \n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2mlwaKlDt_2c"
      },
      "source": [
        "# Create Datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RiG3Ai0uvdc4"
      },
      "outputs": [],
      "source": [
        "train_data = AudioDataset(data_path='/content/data', context = config['context'], offset=config['offset'], partition= \"train\", limit=-1) #Create a dataset object using the AudioDataset class for the training data \n",
        "val_data = AudioDataset(data_path='/content/data', context = config['context'], offset=config['offset'], partition= \"dev\", limit=-1) #Create a dataset object using the AudioDataset class for the training data \n",
        "test_data = AudioTestDataset(data_path='/content/data', context = config['context'], offset=config['offset'], limit=-1) # Create a dataset object using the AudioTestDataset class for the test data "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4mzoYfTKu14s",
        "outputId": "b15b7a2a-edf3-416a-c713-ab83eaad720c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Batch size:  16384\n",
            "Context:  50\n",
            "Input size:  1515\n",
            "Output symbols:  42\n",
            "Train dataset samples = 36191134, batches = 2209\n",
            "Validation dataset samples = 1937496, batches = 119\n",
            "Test dataset samples = 1943253, batches = 119\n"
          ]
        }
      ],
      "source": [
        "# Define dataloaders for train, val and test datasets\n",
        "# Dataloaders will yield a batch of frames and phonemes of given batch_size at every iteration\n",
        "train_loader = torch.utils.data.DataLoader(train_data, num_workers= 4,\n",
        "                                           batch_size=config['batch_size'], pin_memory= True,\n",
        "                                           shuffle= True)\n",
        "\n",
        "val_loader = torch.utils.data.DataLoader(val_data, num_workers= 4,\n",
        "                                         batch_size=config['batch_size'], pin_memory= True,\n",
        "                                         shuffle= False)\n",
        "\n",
        "test_loader = torch.utils.data.DataLoader(test_data, num_workers= 4, \n",
        "                                          batch_size=config['batch_size'], pin_memory= True, \n",
        "                                          shuffle= False)\n",
        "\n",
        "\n",
        "print(\"Batch size: \", config['batch_size'])\n",
        "print(\"Context: \", config['context'])\n",
        "print(\"Input size: \", (2*config['context']+1)*15)\n",
        "print(\"Output symbols: \", len(PHONEMES))\n",
        "\n",
        "print(\"Train dataset samples = {}, batches = {}\".format(train_data.__len__(), len(train_loader)))\n",
        "print(\"Validation dataset samples = {}, batches = {}\".format(val_data.__len__(), len(val_loader)))\n",
        "print(\"Test dataset samples = {}, batches = {}\".format(test_data.__len__(), len(test_loader)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n-GV3UvgLSoF",
        "outputId": "55374885-3022-4472-bd3c-b25489a0ae97"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([16384, 1515]) torch.Size([16384])\n"
          ]
        }
      ],
      "source": [
        "# Testing code to check if data loaders are working\n",
        "for i, data in enumerate(train_loader):\n",
        "    frames, phoneme = data\n",
        "    print(frames.shape, phoneme.shape)\n",
        "    break"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nxjwve20JRJ2"
      },
      "source": [
        "# Network Architecture\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OvcpontXQq9j"
      },
      "outputs": [],
      "source": [
        "from torch.nn.modules.dropout import Dropout\n",
        "from torch.nn.modules.batchnorm import BatchNorm1d\n",
        "\n",
        "class Network(torch.nn.Module):\n",
        "\n",
        "    def __init__(self, context):\n",
        "\n",
        "        super(Network, self).__init__()\n",
        "\n",
        "        input_size = (2*context + 1) * 15 \n",
        "        output_size = 40 \n",
        "        dimension_list = [input_size, 2048, 2048, 2048,2048, 1024,1024,1024, output_size]\n",
        "        #building layers\n",
        "        layers = []\n",
        "        for i in range(len(dimension_list)-2):\n",
        "          layers.append(torch.nn.Linear(dimension_list[i], dimension_list[i+1]))\n",
        "          layers.append(torch.nn.Softplus())\n",
        "          \n",
        "          layers.append(torch.nn.BatchNorm1d(dimension_list[i+1]))\n",
        "          layers.append(torch.nn.Dropout(p = config['dropout']))\n",
        "        \n",
        "        layers.append(torch.nn.LazyLinear(dimension_list[-1]))\n",
        "        self.model = torch.nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "      #col unknown\n",
        "        out = x.reshape((x.shape[0],-1))\n",
        "        for layer in self.model:\n",
        "          out = layer(out)\n",
        "\n",
        "        return out"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HejoSXe3vMVU"
      },
      "source": [
        "# Define Model, Loss Function and Optimizer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xAhGBH7-xxth"
      },
      "source": [
        "Here we define the model, loss function, optimizer and optionally a learning rate scheduler. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RKgcD4YXj5N3"
      },
      "outputs": [],
      "source": [
        "def init_weights(m):\n",
        "    if type(m) == torch.nn.Linear:\n",
        "      #torch.nn.init.xavier_uniform(m.weight)\n",
        "      torch.nn.init.kaiming_normal(m.weight, mode = 'fan_in')\n",
        "      \n",
        "   \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "_qtrEM1ZvLje",
        "outputId": "209f23a7-79a1-45df-842a-8f145fb5616a"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/lazy.py:178: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.\n",
            "  warnings.warn('Lazy modules are a new feature under heavy development '\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:4: UserWarning: nn.init.kaiming_normal is now deprecated in favor of nn.init.kaiming_normal_.\n",
            "  after removing the cwd from sys.path.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "==========================================================================\n",
            "                         Kernel Shape   Output Shape     Params  Mult-Adds\n",
            "Layer                                                                     \n",
            "0_model.Linear_0         [1515, 2048]  [16384, 2048]  3.104768M   3.10272M\n",
            "1_model.Softplus_1                  -  [16384, 2048]          -          -\n",
            "2_model.BatchNorm1d_2          [2048]  [16384, 2048]     4.096k     2.048k\n",
            "3_model.Dropout_3                   -  [16384, 2048]          -          -\n",
            "4_model.Linear_4         [2048, 2048]  [16384, 2048]  4.196352M  4.194304M\n",
            "5_model.Softplus_5                  -  [16384, 2048]          -          -\n",
            "6_model.BatchNorm1d_6          [2048]  [16384, 2048]     4.096k     2.048k\n",
            "7_model.Dropout_7                   -  [16384, 2048]          -          -\n",
            "8_model.Linear_8         [2048, 2048]  [16384, 2048]  4.196352M  4.194304M\n",
            "9_model.Softplus_9                  -  [16384, 2048]          -          -\n",
            "10_model.BatchNorm1d_10        [2048]  [16384, 2048]     4.096k     2.048k\n",
            "11_model.Dropout_11                 -  [16384, 2048]          -          -\n",
            "12_model.Linear_12       [2048, 2048]  [16384, 2048]  4.196352M  4.194304M\n",
            "13_model.Softplus_13                -  [16384, 2048]          -          -\n",
            "14_model.BatchNorm1d_14        [2048]  [16384, 2048]     4.096k     2.048k\n",
            "15_model.Dropout_15                 -  [16384, 2048]          -          -\n",
            "16_model.Linear_16       [2048, 1024]  [16384, 1024]  2.098176M  2.097152M\n",
            "17_model.Softplus_17                -  [16384, 1024]          -          -\n",
            "18_model.BatchNorm1d_18        [1024]  [16384, 1024]     2.048k     1.024k\n",
            "19_model.Dropout_19                 -  [16384, 1024]          -          -\n",
            "20_model.Linear_20       [1024, 1024]  [16384, 1024]    1.0496M  1.048576M\n",
            "21_model.Softplus_21                -  [16384, 1024]          -          -\n",
            "22_model.BatchNorm1d_22        [1024]  [16384, 1024]     2.048k     1.024k\n",
            "23_model.Dropout_23                 -  [16384, 1024]          -          -\n",
            "24_model.Linear_24       [1024, 1024]  [16384, 1024]    1.0496M  1.048576M\n",
            "25_model.Softplus_25                -  [16384, 1024]          -          -\n",
            "26_model.BatchNorm1d_26        [1024]  [16384, 1024]     2.048k     1.024k\n",
            "27_model.Dropout_27                 -  [16384, 1024]          -          -\n",
            "28_model.LazyLinear_28     [1024, 40]    [16384, 40]      41.0k     40.96k\n",
            "--------------------------------------------------------------------------\n",
            "                          Totals\n",
            "Total params          19.954728M\n",
            "Trainable params      19.954728M\n",
            "Non-trainable params         0.0\n",
            "Mult-Adds              19.93216M\n",
            "==========================================================================\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torchsummaryX/torchsummaryX.py:101: FutureWarning: Dropping of nuisance columns in DataFrame reductions (with 'numeric_only=None') is deprecated; in a future version this will raise TypeError.  Select only valid columns before calling the reduction.\n",
            "  df_sum = df.sum()\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-0bafec90-125c-47a6-9017-5212ab3dadc5\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Kernel Shape</th>\n",
              "      <th>Output Shape</th>\n",
              "      <th>Params</th>\n",
              "      <th>Mult-Adds</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Layer</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0_model.Linear_0</th>\n",
              "      <td>[1515, 2048]</td>\n",
              "      <td>[16384, 2048]</td>\n",
              "      <td>3104768.0</td>\n",
              "      <td>3102720.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1_model.Softplus_1</th>\n",
              "      <td>-</td>\n",
              "      <td>[16384, 2048]</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2_model.BatchNorm1d_2</th>\n",
              "      <td>[2048]</td>\n",
              "      <td>[16384, 2048]</td>\n",
              "      <td>4096.0</td>\n",
              "      <td>2048.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3_model.Dropout_3</th>\n",
              "      <td>-</td>\n",
              "      <td>[16384, 2048]</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4_model.Linear_4</th>\n",
              "      <td>[2048, 2048]</td>\n",
              "      <td>[16384, 2048]</td>\n",
              "      <td>4196352.0</td>\n",
              "      <td>4194304.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5_model.Softplus_5</th>\n",
              "      <td>-</td>\n",
              "      <td>[16384, 2048]</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6_model.BatchNorm1d_6</th>\n",
              "      <td>[2048]</td>\n",
              "      <td>[16384, 2048]</td>\n",
              "      <td>4096.0</td>\n",
              "      <td>2048.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7_model.Dropout_7</th>\n",
              "      <td>-</td>\n",
              "      <td>[16384, 2048]</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8_model.Linear_8</th>\n",
              "      <td>[2048, 2048]</td>\n",
              "      <td>[16384, 2048]</td>\n",
              "      <td>4196352.0</td>\n",
              "      <td>4194304.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9_model.Softplus_9</th>\n",
              "      <td>-</td>\n",
              "      <td>[16384, 2048]</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10_model.BatchNorm1d_10</th>\n",
              "      <td>[2048]</td>\n",
              "      <td>[16384, 2048]</td>\n",
              "      <td>4096.0</td>\n",
              "      <td>2048.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11_model.Dropout_11</th>\n",
              "      <td>-</td>\n",
              "      <td>[16384, 2048]</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12_model.Linear_12</th>\n",
              "      <td>[2048, 2048]</td>\n",
              "      <td>[16384, 2048]</td>\n",
              "      <td>4196352.0</td>\n",
              "      <td>4194304.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13_model.Softplus_13</th>\n",
              "      <td>-</td>\n",
              "      <td>[16384, 2048]</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14_model.BatchNorm1d_14</th>\n",
              "      <td>[2048]</td>\n",
              "      <td>[16384, 2048]</td>\n",
              "      <td>4096.0</td>\n",
              "      <td>2048.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15_model.Dropout_15</th>\n",
              "      <td>-</td>\n",
              "      <td>[16384, 2048]</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16_model.Linear_16</th>\n",
              "      <td>[2048, 1024]</td>\n",
              "      <td>[16384, 1024]</td>\n",
              "      <td>2098176.0</td>\n",
              "      <td>2097152.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17_model.Softplus_17</th>\n",
              "      <td>-</td>\n",
              "      <td>[16384, 1024]</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18_model.BatchNorm1d_18</th>\n",
              "      <td>[1024]</td>\n",
              "      <td>[16384, 1024]</td>\n",
              "      <td>2048.0</td>\n",
              "      <td>1024.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19_model.Dropout_19</th>\n",
              "      <td>-</td>\n",
              "      <td>[16384, 1024]</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20_model.Linear_20</th>\n",
              "      <td>[1024, 1024]</td>\n",
              "      <td>[16384, 1024]</td>\n",
              "      <td>1049600.0</td>\n",
              "      <td>1048576.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21_model.Softplus_21</th>\n",
              "      <td>-</td>\n",
              "      <td>[16384, 1024]</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22_model.BatchNorm1d_22</th>\n",
              "      <td>[1024]</td>\n",
              "      <td>[16384, 1024]</td>\n",
              "      <td>2048.0</td>\n",
              "      <td>1024.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23_model.Dropout_23</th>\n",
              "      <td>-</td>\n",
              "      <td>[16384, 1024]</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24_model.Linear_24</th>\n",
              "      <td>[1024, 1024]</td>\n",
              "      <td>[16384, 1024]</td>\n",
              "      <td>1049600.0</td>\n",
              "      <td>1048576.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25_model.Softplus_25</th>\n",
              "      <td>-</td>\n",
              "      <td>[16384, 1024]</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26_model.BatchNorm1d_26</th>\n",
              "      <td>[1024]</td>\n",
              "      <td>[16384, 1024]</td>\n",
              "      <td>2048.0</td>\n",
              "      <td>1024.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27_model.Dropout_27</th>\n",
              "      <td>-</td>\n",
              "      <td>[16384, 1024]</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28_model.LazyLinear_28</th>\n",
              "      <td>[1024, 40]</td>\n",
              "      <td>[16384, 40]</td>\n",
              "      <td>41000.0</td>\n",
              "      <td>40960.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-0bafec90-125c-47a6-9017-5212ab3dadc5')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-0bafec90-125c-47a6-9017-5212ab3dadc5 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-0bafec90-125c-47a6-9017-5212ab3dadc5');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                         Kernel Shape   Output Shape     Params  Mult-Adds\n",
              "Layer                                                                     \n",
              "0_model.Linear_0         [1515, 2048]  [16384, 2048]  3104768.0  3102720.0\n",
              "1_model.Softplus_1                  -  [16384, 2048]        NaN        NaN\n",
              "2_model.BatchNorm1d_2          [2048]  [16384, 2048]     4096.0     2048.0\n",
              "3_model.Dropout_3                   -  [16384, 2048]        NaN        NaN\n",
              "4_model.Linear_4         [2048, 2048]  [16384, 2048]  4196352.0  4194304.0\n",
              "5_model.Softplus_5                  -  [16384, 2048]        NaN        NaN\n",
              "6_model.BatchNorm1d_6          [2048]  [16384, 2048]     4096.0     2048.0\n",
              "7_model.Dropout_7                   -  [16384, 2048]        NaN        NaN\n",
              "8_model.Linear_8         [2048, 2048]  [16384, 2048]  4196352.0  4194304.0\n",
              "9_model.Softplus_9                  -  [16384, 2048]        NaN        NaN\n",
              "10_model.BatchNorm1d_10        [2048]  [16384, 2048]     4096.0     2048.0\n",
              "11_model.Dropout_11                 -  [16384, 2048]        NaN        NaN\n",
              "12_model.Linear_12       [2048, 2048]  [16384, 2048]  4196352.0  4194304.0\n",
              "13_model.Softplus_13                -  [16384, 2048]        NaN        NaN\n",
              "14_model.BatchNorm1d_14        [2048]  [16384, 2048]     4096.0     2048.0\n",
              "15_model.Dropout_15                 -  [16384, 2048]        NaN        NaN\n",
              "16_model.Linear_16       [2048, 1024]  [16384, 1024]  2098176.0  2097152.0\n",
              "17_model.Softplus_17                -  [16384, 1024]        NaN        NaN\n",
              "18_model.BatchNorm1d_18        [1024]  [16384, 1024]     2048.0     1024.0\n",
              "19_model.Dropout_19                 -  [16384, 1024]        NaN        NaN\n",
              "20_model.Linear_20       [1024, 1024]  [16384, 1024]  1049600.0  1048576.0\n",
              "21_model.Softplus_21                -  [16384, 1024]        NaN        NaN\n",
              "22_model.BatchNorm1d_22        [1024]  [16384, 1024]     2048.0     1024.0\n",
              "23_model.Dropout_23                 -  [16384, 1024]        NaN        NaN\n",
              "24_model.Linear_24       [1024, 1024]  [16384, 1024]  1049600.0  1048576.0\n",
              "25_model.Softplus_25                -  [16384, 1024]        NaN        NaN\n",
              "26_model.BatchNorm1d_26        [1024]  [16384, 1024]     2048.0     1024.0\n",
              "27_model.Dropout_27                 -  [16384, 1024]        NaN        NaN\n",
              "28_model.LazyLinear_28     [1024, 40]    [16384, 40]    41000.0    40960.0"
            ]
          },
          "execution_count": 145,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "input_size = 15*(2*config['context'] + 1)\n",
        "model = Network(config['context']).to(device)\n",
        "# Applying initialization to our net\n",
        "model.apply(init_weights)\n",
        "checkpoint_path = '\"./content/drive/MyDrive/11785/HW1/model_checkpoint.pth\"'\n",
        "frames,phoneme = next(iter(train_loader))\n",
        "# Check number of parameters of your network - Remember, you are limited to 20 million parameters for HW1 (including ensembles)\n",
        "summary(model, frames.to(device))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UROGEVJevKD-"
      },
      "outputs": [],
      "source": [
        "criterion = torch.nn.CrossEntropyLoss() #Defining Loss function \n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=config['learning_rate'],weight_decay=config['weight_decay']) #Defining Optimizer\n",
        "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min',patience=5,threshold = 0.001)\n",
        "# Recommended : Define Scheduler for Learning Rate, including but not limited to StepLR, MultiStepLR, CosineAnnealingLR, ReduceLROnPlateau, etc. \n",
        "# You can refer to Pytorch documentation for more information on how to use them."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IBwunYpyugFg"
      },
      "source": [
        "# Training and Validation Functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XblOHEVtKab2",
        "outputId": "e7154868-d670-44d3-e591-ce7854567209"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "2048"
            ]
          },
          "execution_count": 147,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "torch.cuda.empty_cache()\n",
        "gc.collect()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8wjPz7DHqKcL"
      },
      "outputs": [],
      "source": [
        "def train(model, optimizer, criterion, dataloader):\n",
        "\n",
        "    model.train()\n",
        "    train_loss = 0.0 #Monitoring Loss\n",
        "    \n",
        "    for iter, (mfccs, phonemes) in enumerate(dataloader):\n",
        "\n",
        "        ### Move Data to Device (Ideally GPU)\n",
        "        mfccs = mfccs.to(device)\n",
        "        phonemes = phonemes.to(device)\n",
        "\n",
        "        ### Forward Propagation\n",
        "        logits = model(mfccs)\n",
        "\n",
        "        ### Loss Calculation\n",
        "        loss = criterion(logits, phonemes)\n",
        "        train_loss += loss.item()\n",
        "\n",
        "        ### Initialize Gradients\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        ### Backward Propagation\n",
        "        loss.backward()\n",
        "\n",
        "        ### Gradient Descent\n",
        "        optimizer.step()\n",
        "    scheduler.step(loss)\n",
        "  \n",
        "    train_loss /= len(dataloader)\n",
        "    return train_loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q5npQNFH315V"
      },
      "outputs": [],
      "source": [
        "def eval(model, dataloader):\n",
        "\n",
        "    model.eval() # set model in evaluation mode\n",
        "\n",
        "    phone_true_list = []\n",
        "    phone_pred_list = []\n",
        "\n",
        "    for i, data in enumerate(dataloader):\n",
        "\n",
        "        frames, phonemes = data\n",
        "        ### Move data to device (ideally GPU)\n",
        "        frames, phonemes = frames.to(device), phonemes.to(device) \n",
        "\n",
        "        with torch.inference_mode(): # makes sure that there are no gradients computed as we are not training the model now\n",
        "            ### Forward Propagation\n",
        "            logits = model(frames)\n",
        "\n",
        "        ### Get Predictions\n",
        "        predicted_phonemes = torch.argmax(logits, dim=1)\n",
        "        \n",
        "        ### Store Pred and True Labels\n",
        "        phone_pred_list.extend(predicted_phonemes.cpu().tolist())\n",
        "        phone_true_list.extend(phonemes.cpu().tolist())\n",
        "        \n",
        "        # Do you think we need loss.backward() and optimizer.step() here?\n",
        "    \n",
        "        del frames, phonemes, logits\n",
        "        torch.cuda.empty_cache()\n",
        "\n",
        "    ### Calculate Accuracy\n",
        "    accuracy = sklearn.metrics.accuracy_score(phone_pred_list, phone_true_list) \n",
        "    return accuracy*100"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yMd_XxPku5qp"
      },
      "source": [
        "# Weights and Biases Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SCDYx5VEu6qI",
        "outputId": "f8595881-342b-42cf-bff1-c9d19c3262ff"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Calling wandb.login() after wandb.init() has no effect.\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 38,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "wandb.login(key=\"e6c1c51b5a9be1652cd05c3cd971db676b78181f\") #API Key is in your wandb account, under settings (wandb.ai/settings)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 330,
          "referenced_widgets": [
            "c2fa956538f44247bc94ce2cc3bf1622",
            "5f79eb7b17d844ca94c69e1f481a200d",
            "cb462fbb640646b09ff82e1cd5c0654b",
            "9620fbb45d9f48a0bb7c17afeee2591e"
          ]
        },
        "id": "xvUnYd3Bw2up",
        "outputId": "859121e3-4bbd-4562-aa8d-6cdd4a3d4fa9"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "Finishing last run (ID:28t64rzh) before initializing another..."
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c2fa956538f44247bc94ce2cc3bf1622",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "VBox(children=(Label(value='0.003 MB of 0.003 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>train loss</td><td>▁</td></tr><tr><td>validation accuracy</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>train loss</td><td>0.83526</td></tr><tr><td>validation accuracy</td><td>80.80063</td></tr></table><br/></div></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Synced <strong style=\"color:#cdcd00\">high-cutoff2</strong>: <a href=\"https://wandb.ai/jingru-gong/hw1p2/runs/28t64rzh\" target=\"_blank\">https://wandb.ai/jingru-gong/hw1p2/runs/28t64rzh</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Find logs at: <code>./wandb/run-20220925_153609-28t64rzh/logs</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Successfully finished last run (ID:28t64rzh). Initializing new run:<br/>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.13.3"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20220925_155151-2vplklsn</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href=\"https://wandb.ai/jingru-gong/hw1p2/runs/2vplklsn\" target=\"_blank\">high-cutoff2</a></strong> to <a href=\"https://wandb.ai/jingru-gong/hw1p2\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Create your wandb run\n",
        "run = wandb.init(\n",
        "    name = \"high-cutoff2\", ### Wandb creates random run names if you skip this field, we recommend you give useful names\n",
        "    reinit=True, ### Allows reinitalizing runs when you re-run this cell\n",
        "    project=\"hw1p2\", ### Project should be created in your wandb account \n",
        "    config=config ### Wandb Config for your run\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wft15E_IxYFi",
        "outputId": "845599bb-f87f-4d06-c592-41805d21fecf"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['/content/wandb/run-20220925_155151-2vplklsn/files/model_arch.txt']"
            ]
          },
          "execution_count": 151,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "### Save your model architecture as a string with str(model) \n",
        "model_arch = str(model)\n",
        "\n",
        "### Save it in a txt file \n",
        "arch_file = open(\"model_arch.txt\", \"w\")\n",
        "file_write = arch_file.write(model_arch)\n",
        "arch_file.close()\n",
        "\n",
        "### log it in your wandb run with wandb.save()\n",
        "wandb.save('model_arch.txt')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nclx_04fu7Dd"
      },
      "source": [
        "# Experiment"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MdLMWfEpyGOB"
      },
      "source": [
        "Now, it is time to finally run your ablations! Have fun!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/",
          "referenced_widgets": [
            "ef4eea26e722406890c02ad29bac7863"
          ]
        },
        "id": "MG4F77Nm0Am9",
        "outputId": "851e44ae-e928-4e4c-f269-69f9ecf77d4b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 1/90\n",
            "\tTrain Loss: 0.7882\n",
            "\tValidation Accuracy: 81.38%\n",
            "\n",
            "Epoch 2/90\n",
            "\tTrain Loss: 0.5754\n",
            "\tValidation Accuracy: 83.44%\n",
            "\n",
            "Epoch 3/90\n",
            "\tTrain Loss: 0.5209\n",
            "\tValidation Accuracy: 84.34%\n",
            "\n",
            "Epoch 4/90\n",
            "\tTrain Loss: 0.4899\n",
            "\tValidation Accuracy: 84.91%\n",
            "\n",
            "Epoch 5/90\n",
            "\tTrain Loss: 0.4690\n",
            "\tValidation Accuracy: 85.32%\n",
            "\n",
            "Epoch 6/90\n",
            "\tTrain Loss: 0.4533\n",
            "\tValidation Accuracy: 85.63%\n",
            "\n",
            "Epoch 7/90\n",
            "\tTrain Loss: 0.4410\n",
            "\tValidation Accuracy: 85.86%\n",
            "\n",
            "Epoch 8/90\n",
            "\tTrain Loss: 0.4311\n",
            "\tValidation Accuracy: 86.01%\n",
            "\n",
            "Epoch 9/90\n",
            "\tTrain Loss: 0.4228\n",
            "\tValidation Accuracy: 86.14%\n",
            "\n",
            "Epoch 10/90\n",
            "\tTrain Loss: 0.4155\n",
            "\tValidation Accuracy: 86.28%\n",
            "\n",
            "Epoch 11/90\n",
            "\tTrain Loss: 0.4095\n",
            "\tValidation Accuracy: 86.41%\n",
            "\n",
            "Epoch 12/90\n",
            "\tTrain Loss: 0.4040\n",
            "\tValidation Accuracy: 86.49%\n",
            "\n",
            "Epoch 13/90\n",
            "\tTrain Loss: 0.3993\n",
            "\tValidation Accuracy: 86.59%\n",
            "\n",
            "Epoch 14/90\n",
            "\tTrain Loss: 0.3947\n",
            "\tValidation Accuracy: 86.64%\n",
            "\n",
            "Epoch 15/90\n",
            "\tTrain Loss: 0.3909\n",
            "\tValidation Accuracy: 86.74%\n",
            "\n",
            "Epoch 16/90\n",
            "\tTrain Loss: 0.3874\n",
            "\tValidation Accuracy: 86.77%\n",
            "\n",
            "Epoch 17/90\n",
            "\tTrain Loss: 0.3840\n",
            "\tValidation Accuracy: 86.82%\n",
            "\n",
            "Epoch 18/90\n",
            "\tTrain Loss: 0.3811\n",
            "\tValidation Accuracy: 86.86%\n",
            "\n",
            "Epoch 19/90\n",
            "\tTrain Loss: 0.3783\n",
            "\tValidation Accuracy: 86.92%\n",
            "\n",
            "Epoch 20/90\n",
            "\tTrain Loss: 0.3756\n",
            "\tValidation Accuracy: 86.96%\n",
            "\n",
            "Epoch 21/90\n",
            "\tTrain Loss: 0.3733\n",
            "\tValidation Accuracy: 87.00%\n",
            "\n",
            "Epoch 22/90\n",
            "\tTrain Loss: 0.3709\n",
            "\tValidation Accuracy: 87.03%\n",
            "\n",
            "Epoch 23/90\n",
            "\tTrain Loss: 0.3689\n",
            "\tValidation Accuracy: 87.02%\n",
            "\n",
            "Epoch 24/90\n",
            "\tTrain Loss: 0.3669\n",
            "\tValidation Accuracy: 87.10%\n",
            "\n",
            "Epoch 25/90\n",
            "\tTrain Loss: 0.3650\n",
            "\tValidation Accuracy: 87.14%\n",
            "\n",
            "Epoch 26/90\n",
            "\tTrain Loss: 0.3630\n",
            "\tValidation Accuracy: 87.14%\n",
            "\n",
            "Epoch 27/90\n",
            "\tTrain Loss: 0.3615\n",
            "\tValidation Accuracy: 87.17%\n",
            "\n",
            "Epoch 28/90\n",
            "\tTrain Loss: 0.3597\n",
            "\tValidation Accuracy: 87.20%\n",
            "\n",
            "Epoch 29/90\n",
            "\tTrain Loss: 0.3460\n",
            "\tValidation Accuracy: 87.42%\n",
            "\n",
            "Epoch 30/90\n",
            "\tTrain Loss: 0.3412\n",
            "\tValidation Accuracy: 87.45%\n",
            "\n",
            "Epoch 31/90\n",
            "\tTrain Loss: 0.3388\n",
            "\tValidation Accuracy: 87.47%\n",
            "\n",
            "Epoch 32/90\n",
            "\tTrain Loss: 0.3370\n",
            "\tValidation Accuracy: 87.49%\n",
            "\n",
            "Epoch 33/90\n",
            "\tTrain Loss: 0.3360\n",
            "\tValidation Accuracy: 87.52%\n",
            "\n",
            "Epoch 34/90\n",
            "\tTrain Loss: 0.3347\n",
            "\tValidation Accuracy: 87.51%\n",
            "\n",
            "Epoch 35/90\n",
            "\tTrain Loss: 0.3340\n",
            "\tValidation Accuracy: 87.53%\n",
            "\n",
            "Epoch 36/90\n",
            "\tTrain Loss: 0.3332\n",
            "\tValidation Accuracy: 87.53%\n",
            "\n",
            "Epoch 37/90\n",
            "\tTrain Loss: 0.3326\n",
            "\tValidation Accuracy: 87.54%\n",
            "\n",
            "Epoch 38/90\n",
            "\tTrain Loss: 0.3320\n",
            "\tValidation Accuracy: 87.54%\n",
            "\n",
            "Epoch 39/90\n",
            "\tTrain Loss: 0.3313\n",
            "\tValidation Accuracy: 87.55%\n",
            "\n",
            "Epoch 40/90\n",
            "\tTrain Loss: 0.3307\n",
            "\tValidation Accuracy: 87.56%\n",
            "\n",
            "Epoch 41/90\n",
            "\tTrain Loss: 0.3302\n",
            "\tValidation Accuracy: 87.56%\n",
            "\n",
            "Epoch 42/90\n",
            "\tTrain Loss: 0.3290\n",
            "\tValidation Accuracy: 87.57%\n",
            "\n",
            "Epoch 43/90\n",
            "\tTrain Loss: 0.3285\n",
            "\tValidation Accuracy: 87.57%\n",
            "\n",
            "Epoch 44/90\n",
            "\tTrain Loss: 0.3283\n",
            "\tValidation Accuracy: 87.58%\n",
            "\n",
            "Epoch 45/90\n",
            "\tTrain Loss: 0.3282\n",
            "\tValidation Accuracy: 87.58%\n",
            "\n",
            "Epoch 46/90\n",
            "\tTrain Loss: 0.3281\n",
            "\tValidation Accuracy: 87.58%\n",
            "\n",
            "Epoch 47/90\n",
            "\tTrain Loss: 0.3280\n",
            "\tValidation Accuracy: 87.58%\n",
            "\n",
            "Epoch 48/90\n",
            "\tTrain Loss: 0.3279\n",
            "\tValidation Accuracy: 87.58%\n",
            "\n",
            "Epoch 49/90\n",
            "\tTrain Loss: 0.3277\n",
            "\tValidation Accuracy: 87.58%\n",
            "\n",
            "Epoch 50/90\n",
            "\tTrain Loss: 0.3277\n",
            "\tValidation Accuracy: 87.58%\n",
            "\n",
            "Epoch 51/90\n",
            "\tTrain Loss: 0.3278\n",
            "\tValidation Accuracy: 87.58%\n",
            "\n",
            "Epoch 52/90\n",
            "\tTrain Loss: 0.3279\n",
            "\tValidation Accuracy: 87.58%\n",
            "\n",
            "Epoch 53/90\n",
            "\tTrain Loss: 0.3278\n",
            "\tValidation Accuracy: 87.58%\n",
            "\n",
            "Epoch 54/90\n",
            "\tTrain Loss: 0.3277\n",
            "\tValidation Accuracy: 87.58%\n",
            "\n",
            "Epoch 55/90\n",
            "\tTrain Loss: 0.3278\n",
            "\tValidation Accuracy: 87.58%\n",
            "\n",
            "Epoch 56/90\n",
            "\tTrain Loss: 0.3278\n",
            "\tValidation Accuracy: 87.59%\n",
            "\n",
            "Epoch 57/90\n",
            "\tTrain Loss: 0.3279\n",
            "\tValidation Accuracy: 87.59%\n",
            "\n",
            "Epoch 58/90\n",
            "\tTrain Loss: 0.3277\n",
            "\tValidation Accuracy: 87.58%\n",
            "\n",
            "Epoch 59/90\n",
            "\tTrain Loss: 0.3276\n",
            "\tValidation Accuracy: 87.58%\n",
            "\n",
            "Epoch 60/90\n",
            "\tTrain Loss: 0.3276\n",
            "\tValidation Accuracy: 87.58%\n",
            "\n",
            "Epoch 61/90\n",
            "\tTrain Loss: 0.3278\n",
            "\tValidation Accuracy: 87.58%\n",
            "\n",
            "Epoch 62/90\n",
            "\tTrain Loss: 0.3278\n",
            "\tValidation Accuracy: 87.59%\n",
            "\n",
            "Epoch 63/90\n",
            "\tTrain Loss: 0.3277\n",
            "\tValidation Accuracy: 87.58%\n",
            "\n",
            "Epoch 64/90\n",
            "\tTrain Loss: 0.3277\n",
            "\tValidation Accuracy: 87.58%\n",
            "\n",
            "Epoch 65/90\n",
            "\tTrain Loss: 0.3277\n",
            "\tValidation Accuracy: 87.59%\n",
            "\n",
            "Epoch 66/90\n",
            "\tTrain Loss: 0.3278\n",
            "\tValidation Accuracy: 87.58%\n",
            "\n",
            "Epoch 67/90\n",
            "\tTrain Loss: 0.3277\n",
            "\tValidation Accuracy: 87.58%\n",
            "\n",
            "Epoch 68/90\n",
            "\tTrain Loss: 0.3277\n",
            "\tValidation Accuracy: 87.58%\n",
            "\n",
            "Epoch 69/90\n",
            "\tTrain Loss: 0.3278\n",
            "\tValidation Accuracy: 87.58%\n",
            "\n",
            "Epoch 70/90\n",
            "\tTrain Loss: 0.3277\n",
            "\tValidation Accuracy: 87.58%\n",
            "\n",
            "Epoch 71/90\n",
            "\tTrain Loss: 0.3276\n",
            "\tValidation Accuracy: 87.58%\n",
            "\n",
            "Epoch 72/90\n",
            "\tTrain Loss: 0.3277\n",
            "\tValidation Accuracy: 87.58%\n",
            "\n",
            "Epoch 73/90\n",
            "\tTrain Loss: 0.3277\n",
            "\tValidation Accuracy: 87.58%\n",
            "\n",
            "Epoch 74/90\n",
            "\tTrain Loss: 0.3277\n",
            "\tValidation Accuracy: 87.58%\n",
            "\n",
            "Epoch 75/90\n",
            "\tTrain Loss: 0.3277\n",
            "\tValidation Accuracy: 87.58%\n",
            "\n",
            "Epoch 76/90\n",
            "\tTrain Loss: 0.3277\n",
            "\tValidation Accuracy: 87.58%\n",
            "\n",
            "Epoch 77/90\n",
            "\tTrain Loss: 0.3277\n",
            "\tValidation Accuracy: 87.59%\n",
            "\n",
            "Epoch 78/90\n",
            "\tTrain Loss: 0.3276\n",
            "\tValidation Accuracy: 87.58%\n",
            "\n",
            "Epoch 79/90\n",
            "\tTrain Loss: 0.3278\n",
            "\tValidation Accuracy: 87.59%\n",
            "\n",
            "Epoch 80/90\n",
            "\tTrain Loss: 0.3276\n",
            "\tValidation Accuracy: 87.58%\n",
            "\n",
            "Epoch 81/90\n",
            "\tTrain Loss: 0.3277\n",
            "\tValidation Accuracy: 87.58%\n",
            "\n",
            "Epoch 82/90\n",
            "\tTrain Loss: 0.3277\n",
            "\tValidation Accuracy: 87.58%\n",
            "\n",
            "Epoch 83/90\n",
            "\tTrain Loss: 0.3277\n",
            "\tValidation Accuracy: 87.59%\n",
            "\n",
            "Epoch 84/90\n",
            "\tTrain Loss: 0.3278\n",
            "\tValidation Accuracy: 87.58%\n",
            "\n",
            "Epoch 85/90\n",
            "\tTrain Loss: 0.3278\n",
            "\tValidation Accuracy: 87.59%\n",
            "\n",
            "Epoch 86/90\n",
            "\tTrain Loss: 0.3277\n",
            "\tValidation Accuracy: 87.59%\n",
            "\n",
            "Epoch 87/90\n",
            "\tTrain Loss: 0.3279\n",
            "\tValidation Accuracy: 87.58%\n",
            "\n",
            "Epoch 88/90\n",
            "\tTrain Loss: 0.3277\n",
            "\tValidation Accuracy: 87.59%\n",
            "\n",
            "Epoch 89/90\n",
            "\tTrain Loss: 0.3277\n",
            "\tValidation Accuracy: 87.58%\n",
            "\n",
            "Epoch 90/90\n",
            "\tTrain Loss: 0.3278\n",
            "\tValidation Accuracy: 87.58%\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ef4eea26e722406890c02ad29bac7863",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "VBox(children=(Label(value='0.002 MB of 0.002 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>train loss</td><td>█▄▃▃▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>validation accuracy</td><td>▁▄▅▆▇▇▇▇▇▇▇▇████████████████████████████</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>train loss</td><td>0.32779</td></tr><tr><td>validation accuracy</td><td>87.58315</td></tr></table><br/></div></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Synced <strong style=\"color:#cdcd00\">high-cutoff2</strong>: <a href=\"https://wandb.ai/jingru-gong/hw1p2/runs/2vplklsn\" target=\"_blank\">https://wandb.ai/jingru-gong/hw1p2/runs/2vplklsn</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Find logs at: <code>./wandb/run-20220925_155151-2vplklsn/logs</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Iterate over number of epochs to train and evaluate your model\n",
        "torch.cuda.empty_cache()\n",
        "\n",
        "best_acc = 0.0 ### Monitor best accuracy in your run\n",
        "\n",
        "for epoch in range(config['epochs']):\n",
        "    print(\"\\nEpoch {}/{}\".format(epoch+1, config['epochs']))\n",
        "\n",
        "    train_loss = train(model, optimizer, criterion, train_loader)\n",
        "    accuracy = eval(model, val_loader)\n",
        "\n",
        "    print(\"\\tTrain Loss: {:.4f}\".format(train_loss))\n",
        "    print(\"\\tValidation Accuracy: {:.2f}%\".format(accuracy))\n",
        "\n",
        "\n",
        "    ### Log metrics at each epoch in your run - Optionally, you can log at each batch inside train/eval functions (explore wandb documentation/wandb recitation)\n",
        "    wandb.log({\"train loss\": train_loss, \"validation accuracy\": accuracy})\n",
        "\n",
        "    ### Save checkpoint if accuracy is better than your current best\n",
        "    if accuracy >= best_acc:\n",
        "\n",
        "      ### Save checkpoint with information you want\n",
        "      \n",
        "      torch.save({'epoch': epoch,\n",
        "              'model_state_dict': model.state_dict(),\n",
        "              'optimizer_state_dict': optimizer.state_dict(),\n",
        "              'loss': train_loss,\n",
        "              'acc': accuracy}, \n",
        "        './model_checkpoint.pth')\n",
        "      \n",
        "      ### Save checkpoint in wandb\n",
        "      wandb.save('checkpoint.pth')\n",
        "\n",
        "    # Is your training time very high? Look into mixed precision training if your GPU (Tesla T4, V100, etc) can make use of it \n",
        "    # Refer - https://pytorch.org/docs/stable /notes/amp_examples.html\n",
        "\n",
        "### Finish your wandb run\n",
        "run.finish()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_kXwf5YUo_4A"
      },
      "source": [
        "# Testing and submission to Kaggle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "R-SU9fZ3xHtk"
      },
      "outputs": [],
      "source": [
        "def test(model, test_loader):\n",
        "  ### What you call for model to perform inference?\n",
        "  model.eval()\n",
        "\n",
        "  ### List to store predicted phonemes of test data\n",
        "  test_predictions = []\n",
        "\n",
        "  ### Which mode do you need to avoid gradients?\n",
        "  with torch.inference_mode():\n",
        "\n",
        "      for i, frames in enumerate(tqdm(test_loader)):\n",
        "\n",
        "          frames = frames.float().to(device)             \n",
        "          \n",
        "          output = model(frames)\n",
        "\n",
        "          ### Get most likely predicted phoneme with argmax\n",
        "          predicted_phonemes = torch.argmax(output, dim=1)\n",
        "\n",
        "          ### How do you store predicted_phonemes with test_predictions? Hint, look at eval \n",
        "          test_predictions.extend(predicted_phonemes.cpu().tolist())\n",
        "          \n",
        "          \n",
        "  return test_predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "wG9v6Xmxu7wp",
        "outputId": "1912a6ac-ae3d-44a6-f523-a7c9de72d78c"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 119/119 [00:10<00:00, 11.59it/s]\n"
          ]
        }
      ],
      "source": [
        "predictions = test(model, test_loader)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "ZE1hRnvf0bFz"
      },
      "outputs": [],
      "source": [
        "### Create CSV file with predictions\n",
        "with open(\"./submission.csv\", \"w+\") as f:\n",
        "    f.write(\"id,label\\n\")\n",
        "    for i in range(len(predictions)):\n",
        "        f.write(\"{},{}\\n\".format(i, predictions[i]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LjcammuCxMKN",
        "outputId": "31e8cdcc-4bae-48aa-a36f-0619e637e90b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Warning: Looks like you're using an outdated API Version, please consider updating (server 1.5.12 / client 1.5.8)\n",
            "100% 18.6M/18.6M [00:02<00:00, 8.10MB/s]\n",
            "Successfully submitted to Frame-Level Speech Recognition"
          ]
        }
      ],
      "source": [
        "### Submit to kaggle competition using kaggle API\n",
        "!kaggle competitions submit -c 11-785-f22-hw1p2 -f ./submission.csv -m \"Test Submission\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h74BwSIbWr1c"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "background_execution": "on",
      "collapsed_sections": [],
      "machine_shape": "hm",
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3.9.10 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.9.10"
    },
    "vscode": {
      "interpreter": {
        "hash": "b0fa6594d8f4cbf19f97940f81e996739fb7646882a419484c72d19e05852a7e"
      }
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "c2fa956538f44247bc94ce2cc3bf1622": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "VBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5f79eb7b17d844ca94c69e1f481a200d",
              "IPY_MODEL_cb462fbb640646b09ff82e1cd5c0654b"
            ],
            "layout": "IPY_MODEL_9620fbb45d9f48a0bb7c17afeee2591e"
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}